# 공통프로젝트 정리

> 참고사이트
- notion: https://www.notion.so/BOBI-99c240017e584ee1aba5d5fd013e6766
- jira: https://ssafy208.atlassian.net/jira/software/projects/BOBI/boards/1

> 개요 
- 싸피 2학기 공통프로젝트
- 주제: 아이 돌봄이 로봇 보비
- 개발 목적: 최근 맞벌이 가구가 늘면서 3~ 8세의 아이가 혼자 있는 시간이 늘어나 고있다. 하지만 어린이 집에 계속 맡겨 두는것도 가격적으로 부담이 적지 않다. 따라서 로봇이 이를 대체 한다면 장기적으로 봤을때 비용이 절약 될 수 있다. 뿐만 아니라 로봇이 아이와 함께 놀며 아이가 외로움을 느끼지 않도록 도와준다.
- 특징:
  - rspberry pi4
  - esp32
  - servo motor 12개
  - rpi4 <-> esp32 간 uart통신을 함. 따라서 일부처리는 esp32에서 함으로서 rpi4 성능을 유지 할 수 있다.
- 동작 프로세스: 
  - 부모는 휴대폰을 이용하여 아이의 모습을 실시간으로 관찰이 가능하다.
  - 아이의 모습을 영상으로 찍어 클라우드에 저장하여 아이의 노는 모습이 담긴 영상을 평생 간직 할 수 있다.
  - 로봇에 친밀도 시스템을 적용하여 아이가 부모님이 없더라도 불안해 하지 않고 로봇과 함께 친밀감을 쌓으며 잘 지낼 수 있게 한다.

> 사용 툴 
  - git flow (코드 모음)
  - jira (한일 할일 이슈 관리)
  - notion (아이디어 스케치 및 자료 공유)
  - mattermost(메신저 및 공지)
  - docker

> 협업 툴 세부 정리 

- git flow
  - git flow
  - branch를 용도에 맞게 정리
      - master: 최상위 branch
      - release: 배포한 버전
      - develop: 개발하고 있는 버전
      - feature: 세부 구현 모듈
  - commit 내용을 규격화하여 팀원간 어떤 내용을 추가하였는지 한눈에 파악 가능하도록 함.
    - ex) 
- jira
    - 한일 할일 이슈 3가지파트로 나누어 다른 팀원이 어떤 파트를 끝냈고 어떤 파트를 진행해야하는지 한눈에 볼 수 있도록 하는 툴
    - 각각의 이슈에 번호를 붙여 git에 commit을 하는 경우 번호를 함께 작성하여 어떤 이슈에 대한 코드인지 한눈에 볼 수 있도록 정리
    - epic 추가(어떤 일에 해당하는지를 라벨을 달아줌), ex)사전학습, 프로젝트 준비..
      - epic 추가 방법: jira -> 좌측에 issue -> create issue -> 번개모양 epic으로 변경 -> 내용 추가

- notion
  - 일정, 업무, 데이터, 프로젝트 등을 효율적으로 관리 할 수 있는 협업툴
  - ex) 브레인 스토밍, 아이디어 해커톤, 외형 논의, 기술스택 정하기 등등

- mattermost
  - 메세지를 적고 중요 공지등을 올리는 방식으로 활용
  - git 과 jira를 연동하여 새롭게 commit또는 update된 내용을 실시간으로 확인 가능
  
> 사용 기술 스택 & 하드웨어 
- iot
  - Rspberry pi 4 
  - opencv
  - yolo 
  - 아두이노ESP32(로봇 주행관련)
- 웹
  - front-end
    - html5, 바닐라 js, pwa
    - 웹페이지로 구현(어플리케이션은 아님)
    - figma(웹페이지 기초적인 틀을 잡음)
  - back-end
    - 장고
  - DW
    - AWS, 유튜브 스트리밍
    - ERD(데이터 흐름도)
  
> 코드 컨밴션
- 코드 컨밴션이란? 
  - 코드 컨밴션이란 팀원간 코드 분석을 하는 경우 한눈에 알아 볼 수 있도록 코드 레이아웃 규칙을 정하는 것이다. 예를 들면
  ```C++
  for(int i = 0 ; i = 5 ; i ++){
    cout << "HI"
  }

  for(int i = 0 ; i = 5 ; i ++)
  {
    cout << "HI"
  }
  ```
  둘의 출력은 동일하지만 코드 모습이 다르다. 이를 통일하는 작업을 코드 컨밴션이라 한다. 코드 컨밴션은 google의 코드 컨밴션과 동일하게 설정 하였다.
## python <hr>

### 특징

  - PEP8 코드컨벤션 적용
  - vs코드 툴을 사용 
  - 코드 들여쓰기를 할때 tap대신 띄어쓰기를 사용한다. 이유는 python코드의 경우 C와 다르게 괄호대신 들여쓰기로 코드를 구성한다. 이때 tap을 사용하는 사람과 띄어쓰기를 들여쓰기로하는 사람의 혼동을 줄이기 위해서 띄어쓰기로 통일을 한것이다.(띄어쓰기로 하면 귀찮긴하지만 오류 확률이 tap보다 감소한다.)
  - vs 코드 setting 을 마친후 alt+shift+f 를 하면 알아서 레이아웃을 맞춰 준다.
<hr>

### setting 방법 
  
  1.  vs코드 왼쪽 우측 하단 톱니 바퀴를 누른다.
  2. setting를 들어간다.
  3. 검색창에 json을 검색
  4. JSON:schemas 에서 Edit in settings.json 클릭
```py
{
    "[python]": {
        "editor.defaultFormatter": "ms-python.python"
    },
    "workbench.colorTheme": "Default Dark+",
    "window.zoomLevel": 1,
    "json.schemas": [
        
    
    ]
}
```
  5. 위코드로 변경 후 저장 
  6. py 코드 아무코드나 들어가서 alt+shift+f 입력
  7. 무언가 설치를 하겠습니까 뜰떄 '예' or yes
  8. 이후 코드를 작성후 alt+shift+f를 누르면 자동으로 레이아웃이 변경
## C code <hr>

### 특징
  - K&R 방식 사용(google 방식)
  - visiual stdio를 사용

### visiual stdio 세팅 방법

  1. visual studio에서 도구 → 옵션 → 텍스트 편집기 → C/C++ → 서식 → 일반 → 기본 서식 스타일을 Visual Studio에서 Google로 변경
  1. c++ -> 탭 에서 탭 크기를 2로 변경해야 함

  ### 규칙
- typedef는 LinkedList 형식의 PascalCase
- constant 앞에는 k를 붙이고 kPascalCase
- struct 구성 요소는 lower_case
- 함수 이름은 PascalCase
- 지역 변수는 lower_case
- 줄이 길어서 여러 줄에 쓸 때는 논리 연산자 다음에 \n, 첫 줄에 맞춤
- if 쓸 때 이전에 return, break, continue 썼으면 그 뒤에 else 쓰지 말것
- func declare에서 길어질 때는 인자 별로 , 다음에 \n하고 첫 줄에 맞춤, 함수 호출도 동일, 함수 정의도 동일

> 자율 주행(자동 추적)

- ## 특징
  - opencv를 이용하여 타겟을 특정한다.
  - wavego 기존 코드의 camera_opencv 내용을 수정
  - python 기반 

<br>

- ## 추적 및 경로 설정 process

  1. 광각카메라로 영상을 받는다.
  2. 영상을 x,y축으로 좌표화 시킨다. 
  3. 타겟에 사각테두리를 그림.
  4. 사각 테두리의 중심 점을 타겟의 위치로 설정
  5. 좌측에 있으면 좌회전 우측에 있으면 우측으로 이동한다.

<br>

- ## 타겟 설정 방법(3가지 방법)
  - xml file을 이용해서 타겟을 추적
    - 장점: 
      - xml 파일의 학습량이 늘어날 수록 정확하게 탐색이 가능함
      - 자신이 원하는 타겟을 정확하게 탐색가능
    - 단점:
      - xml파일을 생성시 학습시키기 윈한 사진100장, 전혀 상관없는 사진 300장(1:3 비율이 권장)을 준비하고 또한 학습을 시켜야한다.(시간이 오래 걸림)
      - 또한 정확성이 높아질 수록 xml파일의 용량이 커지고 용량이 커질 수록 cpu가 연산해야하는 양이 늘어남(RPI4 기준 70% 사용량)
      - xml 파일 생성시 오류가 많이 발생함.
  - opencv color를 이용
    - 장점: 
      - 구현이 간단하다.
      - cpu 사용량이 비교적 적다.(RPI4 기준 30%)
    - 단점:
      - 색상만으로 구별하기 때문에 만약 동일한 색상의 타겟이 존재한다면 오류가 생김
      - 정확한 타겟 구별이 힘들다.
  - motion get 이용
    - 장점:
      - 화면상 움직이는 대상을 추적한다.
      - 연산량 적음.
    - 단점:
      - 움직이는 대상만 추적하기 때문에 로봇 자체가 움직이는 경우 화면 전체가 움직여 정확한 탐색이 불가능한다.

> BoBi 센서(온도 습도 가스) 통신

- 특징:
  - 센서 2개를 사용 DHT11(온습도) , 가스센서(알콜)
  - mqtt를 이용하여 통신
  - 데이터를 S3로 올림?
  - 3초마다 갱신 설정(실험을 위해 짧은 주기로 갱신)

- mqtt 통신이란?
  - 사물인터넷을 사용하기 위해 개발된 TCP 기반의 프로토콜
  - 낮은 전력, 낮은 대역폭 환경에서도 사용 가능
  - Publisher(라즈베리파이) -> broker -> subscrivber(스마트폰)순으로 통신

> 음성인식(google stt)
- 마이크 2개 사용
- A 마이크는 Hi BoBi를()
- B 마이크는 음성 데이터를 stt로 변환

- feature/voice_recognition 에서 진행

## RPI 세팅

- google stt 진행하던 대로 /home/pi/google_stt 내 설정된 env activate(`source env/bin/activate`)
- `pvporcupine, pvporcupinedemo` 가상 환경 내 설치
- 통합은 /home/pi/voice_recognition에서 진행
    
    ```
    /home/pi/voice_recognition
    	|-- voice_recognition.py
    	|-- porcupine_custom.py
    	|-- connect_porcupine_record.py
    	|-- camera_map_test.py
    ```
    
- 마이크 1개 사용 시
    
    porcupine을 실행 후 stt를 실행하려고 할 때 stt에서 device busy 가 발생
    
    → 마이크 2개 설치(usb 2.0 포트에 하나씩)
    
    `porcupine_demo_mic --show_audio_devices` 통해 연결되어 있는 포트 확인( RPI 부팅될 때마다 바뀜)
    
- 마이크 2개 사용 시 잘 camera_map_test 까지 잘 연동됨
- stt delay 거의 없었음

## 파일 설명

- voice_recognition.py
    - parse_command
        
        stt에 `/home/pi/voice_recognition/파일이름` 을 보내서 text 돌려 받음, 명령어만 파싱
        
    - map_movement
        
        self.var에 담긴 값에 따라 camera_map_test.commandAct 함수 실행
        
    - run
        
        arecord device 1, 0을 이용하여 4초 동안 녹음 진행
        
        parse_command, map_movement 호출
        
- porcupine_custom.py
    - PorcupineCustom
        
        arg로 받은 값대로 porcupine 설정하고 run 함수에서 실행, 만약 hotword 감지되면 전역 변수 hot_word_flag를 1로 설정, 감지 되지 않으면 0으로 설정
        
    - porcupine_parsing
        
        arg 받기 & args로 묶어서 return
        
- connect_porcupine_record.py
    - DetectHotword
        
        hot_word_flag가 1로 설정되면 stt를 실행하는 함수, stt 실행하고 5초 sleep(4초 동안 녹음 + stt 값 받는 시간을 생각해서 설정)
        
    - has_live_threads
        
        살아 있는 thread가 있는지 확인하는 함수
        
    - main
        
        porpupine_parsing을 이용하여 arg 받기
        
        PorcupineCustum에 받은 arg 넣고 thread로 설정
        
        DetectHotword도 thread로 설정
        
        두 thread를 threads array에 넣어 통합적 관리
        
        ctrl+c를 누르면 꺼지도록 설정
        
        (windows에서는 KeyboardInterrupt 시 join을 안 해도 에러 없이 깔끔하게 종료되지만 RPI에서는 해야 에러와 함께 종료됨)
        
- camera_map_test.py
    - camera_opencv를 대신하는 모듈
    - 각각의 명령어에 따라 프린트를 진행하는 commandAct 함수가 있음

## 결과

- RPI의 google_stt를 위해 만든 가상 환경에서 connect_porcupine_record.py가 잘 동작함
- `하이 보비` 로 인식이 된 후 약간 쉬고 명령어를 말해야 잘 녹음됨
- 녹음 파일 이름은 test.wav
    - hotword detect 될 때마다 파일이 갱신됨
- stt delay 거의 없었음
- SSAFY 내 네트워크로는 stt StatusCode.UNAUTHENTICATED 에러가 발생함
→ 핸드폰 핫스팟을 키고 한 번 껐다 키니 바로 잘 됨
- 마이크는 2개 사용
- porcupine을 사용할 때 device_index를 0 제외 다른 것으로 설정(0은 stt에서 녹음할 때 씀)

## 보완할 것

- 현재 2개의 mic를 사용하는데 1개를 사용할 수 있으면 더 좋을 듯
    - pvrecorder를 활용하거나 thread 자체를 잠시 자게 하는 건 어떨까??

> 3D 모델링

- 아이가 다치지 않도록 최대한 곡선을 많이 사용, 또한 외모를 강아지 형태로 제작
- 액상 3D프린터를 사용 (MJP 2500 Plus)
  - 출력최대크기: 294 * 211 * 144
  - 광경화성수지 UV램프 경화
  - 필라멘트 3D 프리터보다 견고하고 정교하게 출력가능. (아이가 가지고 노는 장난감에 쓰이기 때문에 견고하고 표면이 매끈해야한다.)
  - 신속한 테스트
  - 재료와 3D 프린터의 가격이 비교적 비쌈
  - 가이드를 제거하는 후처리 작업이 복잡

> ISSUE

- 220710: 라즈베리파이와 esp32간 uart통신 문제 발생
  - 해결방안: 라즈베리파이에 충분한 전력이 공급되지 못해 전압차가 발생하지 않아 신호를 정확히 판단하지 못함. 추가적인 전력을 라즈베리파이에 공급하여 문제 해결
- 참고자료: wavego_PC connect issue